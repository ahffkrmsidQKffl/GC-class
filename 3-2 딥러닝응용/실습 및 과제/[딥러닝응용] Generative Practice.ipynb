{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f8564d7-90f4-4151-9511-121389ccb6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\강\\appdata\\roaming\\python\\python312\\site-packages (2.5.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp312-cp312-win_amd64.whl.metadata (6.2 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.5.1-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\강\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torchvision-0.20.1-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.6 MB 653.6 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.2/1.6 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.8/1.6 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.6 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 7.1 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.5.1-cp312-cp312-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.4 MB 15.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.1/2.4 MB 13.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.4 MB 12.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.2/2.4 MB 13.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 11.9 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "Successfully installed torchaudio-2.5.1 torchvision-0.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7632fca-c19c-4fa6-a1b8-351b31dd81ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34bdf4f-a05e-4448-8185-01264a4b874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the MNIST data has each data sample with dimensions: 1x28x28\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=4, stride=2, padding=1)  \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1)              \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)  \n",
    "           \n",
    "        self.fc_mu = nn.Linear(128 * 4 * 4, z_dim)\n",
    "        self.fc_logvar = nn.Linear(128 * 4 * 4, z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.conv1(x)) # 1x28x28 -> 32x14x14\n",
    "        h = F.relu(self.conv2(h)) # 32x14x14 -> 64x7x7\n",
    "        h = F.relu(self.conv3(h)) # 64x7x7 -> 128x4x4\n",
    "        h = h.view(h.size(0), -1) # 128x4x4 -> 128x16 (just to \"concatenate all 2D data into 1 single dimension\")\n",
    "        \n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e4dba1e-0d84-4280-ac01-4a05bd4684f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim, output_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Linear(z_dim, 128 * 4 * 4)\n",
    "        self.deconv1 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1)  # 4x4 -> 8x8\n",
    "        self.deconv2 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)                    # 8x8 -> 16x16\n",
    "        self.deconv3 = nn.ConvTranspose2d(32, output_channels, kernel_size=4, stride=2, padding=1)       # 16x16 -> 32x32\n",
    "        self.output_layer = nn.Conv2d(output_channels, output_channels, kernel_size=5, stride=1, padding=0)  # 32x32 -> 28x28\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = F.relu(self.fc(z))\n",
    "        h = h.view(-1, 128, 4, 4)\n",
    "        h = F.relu(self.deconv1(h))\n",
    "        h = F.relu(self.deconv2(h))\n",
    "        h = F.relu(self.deconv3(h))\n",
    "        x_recon = torch.sigmoid(self.output_layer(h))\n",
    "        return x_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2897c73e-ec40-4360-bd0a-5ee488d5e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(input_channels, hidden_dim, z_dim)\n",
    "        self.decoder = Decoder(z_dim, hidden_dim, input_channels)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std) #here is the assumption p(z)=N(0,I)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "#criterion = nn.MSELoss(reduction='sum')\n",
    "criterion = nn.BCELoss(reduction='sum')\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    MSE = criterion(recon_x, x)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return MSE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7adbcdc2-c7b4-4e11-a676-557922573e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalEncoder(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim, z_dim, num_classes):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1 = nn.Conv2d(input_channels + num_classes, 32, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.fc_mu = nn.Linear(128 * 4 * 4, z_dim)\n",
    "        self.fc_logvar = nn.Linear(128 * 4 * 4, z_dim)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "\n",
    "        # one-hot encode labels and expand dimensions shape [batch_size, num_classes, spatialY, spatialX],\n",
    "        y = one_hot_encode(labels, self.num_classes).unsqueeze(2).unsqueeze(3) # [64, 10, 1, 1]\n",
    "        y = y.expand(-1, -1, x.size(2), x.size(3)) #[64, 10, 28, 28] make a \"layer of conditional information\"\n",
    "        # concatenate along the channel dimension\n",
    "        x = torch.cat([x, y], dim=1)\n",
    "\n",
    "\n",
    "        h = F.relu(self.conv1(x))\n",
    "        h = F.relu(self.conv2(h))\n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = h.view(h.size(0), -1)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9f0066c-94c8-45f9-8e9b-05b5b028ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar, beta=1.0):\n",
    "    BCE = criterion(recon_x, x)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + beta * KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9936a5e5-4898-4d43-a7de-58f86165fe3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
